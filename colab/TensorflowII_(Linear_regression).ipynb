{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorflowII (Linear regression).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_wxFzcyM8Lb2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Read a csv file in memory"
      ]
    },
    {
      "metadata": {
        "id": "5-qgFzSsMOkC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, read the csv file with pandas (dataframe)\n",
        "\n",
        "Plot a scatter for `JPM` (JP Morgan) vs `AXP` (American Express) to visually look at correlation."
      ]
    },
    {
      "metadata": {
        "id": "sSZnBYGA8Ca0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "44Hkf4iR8Pf9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fileurl = \"https://s3-eu-west-1.amazonaws.com/training180529/data/djia_close.csv\"\n",
        "\n",
        "df = pd.read_csv(fileurl, sep=',',header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "339vo7Uv8SxM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(df[['AXP']], df[['JPM']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qcNiTI3hOiCb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Sort and index by date"
      ]
    },
    {
      "metadata": {
        "id": "VFq_iegR8XcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values(by= 'date').reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mj1NR7UBOpN7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[['AXP', 'JPM', 'IBM']].plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZhkDMRjdOy_E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Some data cleaning: identify columns with at least one NaN"
      ]
    },
    {
      "metadata": {
        "id": "nXvNFErZOrks",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.columns[df.isna().any()].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_s9zdGgXU-r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Linear model"
      ]
    },
    {
      "metadata": {
        "id": "daE3AaSeX5ud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rH0cRqhNO5Tl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  x = tf.constant(df[['AXP']])\n",
        "  y = tf.constant(df[['JPM']])\n",
        "  \n",
        "  weights = tf.Variable(tf.random_normal([1, 1], 0, .1, dtype=tf.float64))\n",
        "  yhat = x @ weights\n",
        "  \n",
        "  yerror = tf.subtract(yhat, y)\n",
        "  loss = tf.reduce_sum(tf.multiply(yerror, yerror))\n",
        "  \n",
        "  tf.global_variables_initializer().run()\n",
        "  sess.run(loss)\n",
        "  \n",
        "  print(loss.eval())\n",
        "  print(weights.eval())\n",
        "  \n",
        "  plt.plot(range(y.eval().shape[0]), y.eval(), 'g-')\n",
        "  plt.plot(range(y.eval().shape[0]), yhat.eval(), 'b-')\n",
        "  plt.plot(yerror.eval(), 'r-')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "icHPc5dXYbkv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Manual guess of parameter: \n",
        "\n",
        "The average price of `JPM` divided by `AXP` is a good weight guess, here is a compute of mean ratio:"
      ]
    },
    {
      "metadata": {
        "id": "vz0kctAQX17S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  x = tf.constant(df[['AXP']])\n",
        "  y = tf.constant(df[['JPM']])\n",
        "  \n",
        "  x_m = tf.reduce_mean(y / x)\n",
        "  print(x_m.eval())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cp0MLb37Z1b6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### grid search of optimal weight"
      ]
    },
    {
      "metadata": {
        "id": "-yzcB3tOY_1W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "ws = []\n",
        "gradients = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  x = tf.constant(df[['AXP']])\n",
        "  y = tf.constant(df[['JPM']])\n",
        "  \n",
        "  weights = tf.Variable(tf.random_normal([1, 1], 0, .1, dtype=tf.float64))\n",
        "  yhat = x @ weights\n",
        "  \n",
        "  yerror = tf.subtract(yhat, y)\n",
        "  loss = 0.5 * tf.reduce_sum(tf.multiply(yerror, yerror))\n",
        "  gradient = tf.reduce_sum(tf.transpose(tf.multiply(x, yerror)), 1, keep_dims=True)\n",
        "  \n",
        "  update_weights = tf.assign(weights, weights + 0.1)\n",
        "  \n",
        "  tf.global_variables_initializer().run()\n",
        "  \n",
        "  for i in range(20):\n",
        "    sess.run([loss, update_weights])\n",
        "    losses.append(loss.eval())\n",
        "    ws.append(weights.eval()[0])\n",
        "    gradients.append(gradient.eval()[0])\n",
        "  fig, ax1 = plt.subplots()\n",
        "  color = 'tab:red'\n",
        "  ax1.set_xlabel('weight')\n",
        "  ax1.set_ylabel('Loss', color=color)\n",
        "  ax1.plot(ws, losses, color=color)\n",
        "  ax1.tick_params(axis='y', labelcolor=color)\n",
        "  \n",
        "  ax2 = ax1.twinx()\n",
        "  color = 'tab:blue'\n",
        "  ax2.set_ylabel('Gradient', color=color) \n",
        "  ax2.plot(ws, gradients, color=color)\n",
        "  ax2.tick_params(axis='y', labelcolor=color)\n",
        "  fig.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Csi_85xjajDT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "ws = []\n",
        "gradients = []\n",
        "\n",
        "learning_rate = 1e-6\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  x = tf.constant(df[['AXP']])\n",
        "  y = tf.constant(df[['JPM']])\n",
        "  \n",
        "  weights = tf.Variable(tf.random_normal([1, 1], 0, .1, dtype=tf.float64))\n",
        "  yhat = x @ weights\n",
        "  \n",
        "  yerror = tf.subtract(yhat, y)\n",
        "  loss = 0.5 * tf.reduce_sum(tf.multiply(yerror, yerror))\n",
        "  gradient = tf.reduce_sum(tf.transpose(tf.multiply(x, yerror)), 1, keep_dims=True)\n",
        "  \n",
        "  update_weights = tf.assign_sub(weights, learning_rate * gradient)\n",
        "  \n",
        "  tf.global_variables_initializer().run()\n",
        "  \n",
        "  for i in range(20):\n",
        "    sess.run([loss, update_weights])\n",
        "    \n",
        "    losses.append(loss.eval())\n",
        "    ws.append(weights.eval()[0])\n",
        "    gradients.append(gradient.eval()[0])\n",
        "    \n",
        "    \n",
        "  fig, axes = plt.subplots(1, 2)\n",
        "  ax1 = axes[0]\n",
        "  color = 'tab:red'\n",
        "  ax1.set_xlabel('weight')\n",
        "  ax1.set_ylabel('Loss', color=color)\n",
        "  ax1.plot(ws, losses, color=color)\n",
        "  ax1.tick_params(axis='y', labelcolor=color)\n",
        "  \n",
        "  ax2 = ax1.twinx()\n",
        "  color = 'tab:blue'\n",
        "  ax2.set_ylabel('Gradient', color=color) \n",
        "  ax2.plot(ws, gradients, color=color)\n",
        "  ax2.tick_params(axis='y', labelcolor=color)\n",
        "  \n",
        "  axes[1].plot(losses)\n",
        "  fig.tight_layout()\n",
        "  \n",
        "  print(weights.eval())\n",
        "  print(loss.eval())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxIkP7JFke4k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Use GradientDescentOptimizer"
      ]
    },
    {
      "metadata": {
        "id": "N2jUkipAeuho",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "ws = []\n",
        "\n",
        "learning_rate = 1e-6\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  x = tf.constant(df[['AXP']])\n",
        "  y = tf.constant(df[['JPM']])\n",
        "  \n",
        "  weights = tf.Variable(tf.random_normal([1, 1], 0, .1, dtype=tf.float64))\n",
        "  b = tf.Variable(tf.random_normal([1, 1], 0, .1, dtype=tf.float64))\n",
        "  yhat = x @ weights + b\n",
        "  \n",
        "  yerror = tf.subtract(yhat, y)\n",
        "  loss = tf.nn.l2_loss(yerror)\n",
        "  \n",
        "  update_weights = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "  \n",
        "  tf.global_variables_initializer().run()\n",
        "  \n",
        "  for i in range(20):\n",
        "    sess.run([loss, update_weights])\n",
        "    \n",
        "    losses.append(loss.eval())\n",
        "    ws.append(weights.eval()[0])\n",
        "    gradients.append(gradient.eval()[0])\n",
        "    \n",
        "    \n",
        "  fig, axes = plt.subplots(1, 2)\n",
        "  ax1 = axes[0]\n",
        "  color = 'tab:red'\n",
        "  ax1.set_xlabel('weight')\n",
        "  ax1.set_ylabel('Loss', color=color)\n",
        "  ax1.plot(ws, losses, color=color)\n",
        "  ax1.tick_params(axis='y', labelcolor=color)\n",
        "  \n",
        "  axes[1].plot(losses)\n",
        "  fig.tight_layout()\n",
        "  \n",
        "  print(weights.eval())\n",
        "  print(b.eval())\n",
        "  print(loss.eval())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ACTl0V6Jk488",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}