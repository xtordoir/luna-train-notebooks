{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "Data is taken from tutorials available in tensorflow\n",
    "\n",
    "MNIST is a set of images of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c23211f5c157>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "def gen_image(arr):\n",
    "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
    "    plt.imshow(two_d, interpolation='nearest')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_xs, batch_ys = mnist.test.next_batch(2)\n",
    "gen_image(batch_xs[0]).show()\n",
    "gen_image(batch_xs[1]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, 28*28])\n",
    "Y = tf.placeholder(\"float\", [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose matrix and assign names to columns (pixel number)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input():\n",
    "     mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((mnist.train.images,\n",
    "                                              mnist.train.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create features column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "numeric_column() missing 1 required positional argument: 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8c4c7906c839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmy_feature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmy_feature_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumeric_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: numeric_column() missing 1 required positional argument: 'key'"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = list(range(1, 1))\n",
    "for key in range(1, 28*28):\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpfi6i6y2u\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpfi6i6y2u', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f692bdee9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers and 10 nodes in each hidden layer.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=[],\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[256, 256],\n",
    "    # The model must choose between 10 classes.\n",
    "    n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorSliceDataset' object has no attribute 'next_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-df2795613a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m classifier.train(\n\u001b[1;32m      3\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     steps=10)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    851\u001b[0m       features, labels, input_hooks = (\n\u001b[1;32m    852\u001b[0m           self._get_features_and_labels_from_input_fn(\n\u001b[0;32m--> 853\u001b[0;31m               input_fn, model_fn_lib.ModeKeys.TRAIN))\n\u001b[0m\u001b[1;32m    854\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m       estimator_spec = self._call_model_fn(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m    689\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_features_and_labels_from_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m     \u001b[0;31m# TODO(anjalisridhar): What about the default DistributionStrategy? Perhaps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;31m# using any input is alright in that case. There is also a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-df2795613a66>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the Model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m classifier.train(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     steps=10)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorSliceDataset' object has no attribute 'next_batch'"
     ]
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda: dataset.next_batch(10),\n",
    "    steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:new_data.eval_input_fn(test_x, test_y, args.batch_size))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:new_data.eval_input_fn(predict_x,\n",
    "                                            batch_size=args.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
